{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import time\n",
    "import pickle\n",
    "import urllib.request\n",
    "from itertools import product\n",
    "from random import randrange\n",
    "\n",
    "\n",
    "\n",
    "raw_data_path='../data/raw_data_all_positions.pkl'\n",
    "parsed_data_path='../data/parsed_data_all_positions.pkl'\n",
    "\n",
    "# PyPI imports\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Set the data file paths\n",
    "raw_data_path='../data/raw_data_all_positions.pkl'\n",
    "parsed_data_path='../data/parsed_data_all_positions.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_url(url: str) -> bytes:\n",
    "    '''Takes string url, downloads URL and returns HTML bytes object'''\n",
    "\n",
    "    headers={\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Host\": \"httpbin.io\",\n",
    "        \"Sec-Ch-Ua\": '\"Google Chrome\";v=\"131\", \"Chromium\";v=\"131\", \"Not_A Brand\";v=\"24\"',\n",
    "        \"Sec-Ch-Ua-Mobile\": \"?0\",\n",
    "        \"Sec-Ch-Ua-Platform\": '\"Linux\"',\n",
    "        \"Sec-Fetch-Dest\": \"document\",\n",
    "        \"Sec-Fetch-Mode\": \"navigate\",\n",
    "        \"Sec-Fetch-Site\": \"cross-site\",\n",
    "        \"Sec-Fetch-User\": \"?1\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    # Create the request\n",
    "    request_params = urllib.request.Request(\n",
    "        url=url,\n",
    "        headers=headers\n",
    "    )   \n",
    "\n",
    "    # Get the html\n",
    "    with urllib.request.urlopen(request_params) as response:\n",
    "        html=response.read()\n",
    "\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html_table(html: bytes, year: int, week: int, profile: str) -> pd.DataFrame:\n",
    "    '''Takes a html bytes object from URL, parses data table, adds\n",
    "    year, week, position and scoring profile and returns as pandas dataframe'''\n",
    "\n",
    "    # Extract the table rows\n",
    "    soup=BeautifulSoup(html, 'html.parser')\n",
    "    table=soup.find('table',{'class':'datasmall table'})\n",
    "    table_rows=table.find_all('tr')\n",
    "\n",
    "    # Get the column names from the first row\n",
    "    columns=table_rows[0].find_all('th')\n",
    "    column_names=[column.getText() for column in columns]\n",
    "    column_names.extend(['Year', 'Week', 'Scoring profile'])\n",
    "\n",
    "    # Get the values for each row\n",
    "    data=[]\n",
    "\n",
    "    for row in table_rows[1:]:\n",
    "        columns=row.find_all('td')\n",
    "        values=[column.getText() for column in columns]\n",
    "        values.extend([year, week, profile])\n",
    "        data.append(values)\n",
    "\n",
    "    # Convert to pandas dataframe and return\n",
    "    return pd.DataFrame(columns=column_names, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from file\n",
      "\n",
      "CPU times: user 17 ms, sys: 23.1 ms, total: 40 ms\n",
      "Wall time: 45.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Main script to download data\n",
    "download_data = False  # Or False, depending on what you want to do\n",
    "\n",
    "if download_data is True:\n",
    "    positions = ['qb', 'rb', 'wr', 'te']\n",
    "    profile = 'p'\n",
    "    years = list(range(2020, 2024))\n",
    "    weeks = list(range(1, 19))\n",
    "\n",
    "    # Empty dict. to store dataframes for each position\n",
    "    position_data={}\n",
    "\n",
    "    # Loop on positions first, and create a separate dataframe for each\n",
    "    for position in positions:\n",
    "\n",
    "        # Empty list to collect data for this position\n",
    "        results = []\n",
    "\n",
    "        for year, week in product(years, weeks):\n",
    "            print(f'Downloading {position.upper()}, {year}, week {week}', end='\\r')\n",
    "            url = f'https://www.footballguys.com/playerhistoricalstats?pos={position}&yr={year}&startwk={week}&stopwk={week}&profile={profile}'\n",
    "            \n",
    "            # Get the HTML\n",
    "            html = download_url(url)\n",
    "            \n",
    "            # Parse the HTML\n",
    "            result = parse_html_table(html, year, week, profile)\n",
    "            \n",
    "            # Collect the result\n",
    "            results.append(result)\n",
    "\n",
    "            # Wait before downloading the next page\n",
    "            time.sleep(randrange(1, 5))\n",
    "\n",
    "        # Combine the week-by-week dataframes\n",
    "        data_df = pd.concat(results)\n",
    "\n",
    "        # Add the dataframe for this position to the collection\n",
    "        position_data[position]=data_df\n",
    "    \n",
    "    # Save the raw data\n",
    "    pickle.dump(position_data, open(raw_data_path, 'wb'))\n",
    "    \n",
    "elif download_data is False:\n",
    "    position_data = pickle.load(open(raw_data_path, 'rb'))\n",
    "    print('Loaded data from file', end='')\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Position: qb\n",
      "\n",
      "  Rank                Name   Age   Exp  G Cmp Att   Cm%  PYd  Y/Att PTD Int  \\\n",
      "0    1      Josh Allen BUF  24.0   3.0  1  33  46  71.7  312   6.78   2   0   \n",
      "1    2  Russell Wilson SEA  32.0   9.0  1  31  35  88.6  322   9.20   4   0   \n",
      "2    3    Aaron Rodgers GB  37.0  16.0  1  32  44  72.7  364   8.27   4   0   \n",
      "3    4   Lamar Jackson BAL  23.0   3.0  1  20  25  80.0  275  11.00   3   0   \n",
      "4    5    Kyler Murray ARI  23.0   2.0  1  26  40  65.0  230   5.75   1   1   \n",
      "\n",
      "  Rsh RshYd RshTD  FP/G FantPt  Year  Week Scoring profile  \n",
      "0  14    57     1  32.2   32.2  2020     1               p  \n",
      "1   3    29     0  31.8   31.8  2020     1               p  \n",
      "2   1     2     0  30.8   30.8  2020     1               p  \n",
      "3   7    45     0  27.5   27.5  2020     1               p  \n",
      "4  13    91     1  26.3   26.3  2020     1               p  \n",
      "\n",
      "Position: rb\n",
      "\n",
      "  Rank                     Name   Age  Exp  G Rsh RshYd Y/Rsh RshTD Rec RecYd  \\\n",
      "0    1           Josh Jacobs LV  22.0  2.0  1  25    93   3.7     3   4    46   \n",
      "1    2  Christian McCaffrey CAR  24.0  4.0  1  23    96   4.2     2   3    38   \n",
      "2    3      Ezekiel Elliott DAL  25.0  5.0  1  22    96   4.4     1   3    31   \n",
      "3    4         Nyheim Hines IND  24.0  3.0  1   7    28   4.0     1   8    45   \n",
      "4    5        Malcolm Brown LAR  27.0  6.0  1  18    79   4.4     2   3    31   \n",
      "\n",
      "  RecTD  FP/G FantPt  Year  Week Scoring profile  \n",
      "0     0  35.9   35.9  2020     1               p  \n",
      "1     0  28.4   28.4  2020     1               p  \n",
      "2     1  27.7   27.7  2020     1               p  \n",
      "3     1  27.3   27.3  2020     1               p  \n",
      "4     0  26.0   26.0  2020     1               p  \n",
      "\n",
      "Position: wr\n",
      "\n",
      "  Rank                 Name   Age  Exp  G Rsh RshYd RshTD Rec RecYd Y/Rec  \\\n",
      "0    1     Davante Adams GB  28.0  7.0  1   0     0     0  14   156  11.1   \n",
      "1    2    Calvin Ridley ATL  26.0  3.0  1   1    -1     0   9   130  14.4   \n",
      "2    3  DeAndre Hopkins ARI  28.0  8.0  1   0     0     0  14   151  10.8   \n",
      "3    4     Adam Thielen MIN  30.0  8.0  1   0     0     0   6   110  18.3   \n",
      "4    5   Darius Slayton NYG  23.0  2.0  1   0     0     0   6   102  17.0   \n",
      "\n",
      "  RecTD  FP/G FantPt  Year  Week Scoring profile  \n",
      "0     2  41.6   41.6  2020     1               p  \n",
      "1     2  33.9   33.9  2020     1               p  \n",
      "2     0  29.1   29.1  2020     1               p  \n",
      "3     2  29.0   29.0  2020     1               p  \n",
      "4     2  28.2   28.2  2020     1               p  \n",
      "\n",
      "Position: te\n",
      "\n",
      "  Rank                Name   Age  Exp  G Rec RecYd Y/Rec RecTD  FP/G FantPt  \\\n",
      "0    1  Dallas Goedert PHI  25.0  3.0  1   8   101  12.6     1  24.1   24.1   \n",
      "1    2    Mark Andrews BAL  25.0  3.0  1   5    58  11.6     2  22.8   22.8   \n",
      "2    3       Noah Fant DEN  23.0  2.0  1   5    81  16.2     1  19.1   19.1   \n",
      "3    4     Travis Kelce KC  31.0  8.0  1   6    50   8.3     1  17.0   17.0   \n",
      "4    5  T.J. Hockenson DET  23.0  2.0  1   5    56  11.2     1  16.6   16.6   \n",
      "\n",
      "   Year  Week Scoring profile  \n",
      "0  2020     1               p  \n",
      "1  2020     1               p  \n",
      "2  2020     1               p  \n",
      "3  2020     1               p  \n",
      "4  2020     1               p  \n"
     ]
    }
   ],
   "source": [
    "# Take a look at the result\n",
    "for position, data_df in position_data.items():\n",
    "    print(f'\\nPosition: {position}\\n')\n",
    "    print(data_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
